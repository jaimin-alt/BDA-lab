{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd5aac86-faac-49e1-9f8d-828e06a074af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/jaimin/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/jaimin/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import lower, regexp_replace, when\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover\n",
    "\n",
    "import random\n",
    "import nltk\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"omw-1.4\")\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer as KTokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Bidirectional, Dense, Dropout\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"AmazonSentimentBiLSTM\") \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2fe7bfe-05ea-4670-ab72-3fb22465d7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path):\n",
    "    df = spark.read.csv(\n",
    "        path,\n",
    "        header=False,\n",
    "        inferSchema=True\n",
    "    )\n",
    "    df = df.toDF(\"rating\", \"review_title\", \"review_text\")\n",
    "\n",
    "    df = df.withColumn(\n",
    "        \"sentiment\",\n",
    "        when(df.rating >= 3, \"positive\").otherwise(\"negative\")\n",
    "    )\n",
    "\n",
    "    return df.select(\"review_text\", \"sentiment\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9a79d76-1eeb-439d-821a-245b460fadc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------+\n",
      "|review_text                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |sentiment|\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------+\n",
      "|This sound track was beautiful! It paints the senery in your mind so well I would recomend it even to people who hate vid. game music! I have played the game Chrono Cross but out of all of the games I have ever played it has the best music! It backs away from crude keyboarding and takes a fresher step with grate guitars and soulful orchestras. It would impress anyone who cares to listen! ^_^                                                                            |negative |\n",
      "|I'm reading a lot of reviews saying that this is the best 'game soundtrack' and I figured that I'd write a review to disagree a bit. This in my opinino is Yasunori Mitsuda's ultimate masterpiece. The music is timeless and I'm been listening to it for years now and its beauty simply refuses to fade.The price tag on this is pretty staggering I must say, but if you are going to buy any cd for this much money, this is the only one that I feel would be worth every penny.|negative |\n",
      "|\"This soundtrack is my favorite music of all time, hands down. The intense sadness of \"\"Prisoners of Fate\"\" (which means all the more if you've played the game) and the hope in \"\"A Distant Promise\"\" and \"\"Girl who Stole the Star\"\" have been an important inspiration to me personally throughout my teen years. The higher energy tracks like \"\"Chrono Cross ~ Time's Scar~\"\"                                                                                                    |negative |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df = load_dataset(\"data/train.csv\")\n",
    "test_df  = load_dataset(\"data/test.csv\")\n",
    "\n",
    "train_df.show(3, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec0a170e-f802-4235-89e5-0d3356f37a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, lower, regexp_replace, trim\n",
    "\n",
    "def spark_preprocess(df):\n",
    "    # âœ… Replace NULL text with empty string\n",
    "    df = df.fillna({\"review_text\": \"\"})\n",
    "\n",
    "    # âœ… Clean text\n",
    "    df = df.withColumn(\n",
    "        \"clean_text\",\n",
    "        trim(lower(regexp_replace(col(\"review_text\"), \"[^a-zA-Z\\\\s]\", \"\")))\n",
    "    )\n",
    "\n",
    "    # âœ… Drop rows that are empty AFTER cleaning\n",
    "    df = df.filter(col(\"clean_text\") != \"\")\n",
    "\n",
    "    # âœ… Tokenization (SAFE now)\n",
    "    tokenizer = Tokenizer(\n",
    "        inputCol=\"clean_text\",\n",
    "        outputCol=\"tokens\"\n",
    "    )\n",
    "    df = tokenizer.transform(df)\n",
    "\n",
    "    # âœ… Stopword removal\n",
    "    remover = StopWordsRemover(\n",
    "        inputCol=\"tokens\",\n",
    "        outputCol=\"filtered_tokens\"\n",
    "    )\n",
    "    df = remover.transform(df)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79c8ef1c-ed4d-4ff9-a591-b80a327456dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = spark_preprocess(train_df)\n",
    "test_df  = spark_preprocess(test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6f54fc6-907e-4797-832f-34118c7d655b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = train_df.randomSplit([0.875, 0.125], seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f155d8cd-000f-470a-acd4-6d017cf161fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = split_train_val(train_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82d7c6cc-66e3-4b9a-9483-f8c49b203012",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spark_to_python(df, limit):\n",
    "    df = df.limit(limit)   # ğŸ”¥ CRITICAL\n",
    "\n",
    "    data = df.select(\"filtered_tokens\", \"sentiment\") \\\n",
    "        .rdd.map(\n",
    "            lambda x: (\" \".join(x[0]), 1 if x[1] == \"positive\" else 0)\n",
    "        ).collect()\n",
    "\n",
    "    texts, labels = zip(*data)\n",
    "    return list(texts), list(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc944630-9269-4ec5-9709-6adc69937acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/plain": [
       "(40000, 5000, 10000)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train = spark_to_python(train_df, limit=40000)\n",
    "X_val, y_val     = spark_to_python(val_df,   limit=5000)\n",
    "X_test, y_test   = spark_to_python(test_df,  limit=10000)\n",
    "\n",
    "len(X_train), len(X_val), len(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8703248c-544c-46da-9435-e4c1bbcda84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Bidirectional, Dense, Dropout\n",
    "\n",
    "def vectorize_text(X_train, X_val, X_test, max_words=20000, max_len=200):\n",
    "    tokenizer = Tokenizer(\n",
    "        num_words=max_words,\n",
    "        oov_token=\"<OOV>\"\n",
    "    )\n",
    "    tokenizer.fit_on_texts(X_train)   # â— train data only\n",
    "\n",
    "    def encode(texts):\n",
    "        seq = tokenizer.texts_to_sequences(texts)\n",
    "        return pad_sequences(seq, maxlen=max_len)\n",
    "\n",
    "    return (\n",
    "        encode(X_train),\n",
    "        encode(X_val),\n",
    "        encode(X_test),\n",
    "        tokenizer\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "29649d75-e407-4b9d-9c26-425a59c61643",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_seq, X_val_seq, X_test_seq, keras_tokenizer = vectorize_text(\n",
    "    X_train, X_val, X_test\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7d74bf91-9082-49d3-a6d6-1482ff2f9499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 200)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_seq.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2590fb51-7edc-460e-a0ab-9ba9dea5675a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Bidirectional, Dense, Dropout\n",
    "\n",
    "def build_bilstm(vocab_size=20000, embed_dim=128, max_len=200):\n",
    "    model = Sequential([\n",
    "        Embedding(vocab_size, embed_dim, input_length=max_len),\n",
    "        Bidirectional(LSTM(64, return_sequences=True)),\n",
    "        Dropout(0.5),\n",
    "        Bidirectional(LSTM(32)),\n",
    "        Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0c320122-43fa-442e-9618-34a4bcac9696",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_train_seq = np.array(X_train_seq)\n",
    "X_val_seq   = np.array(X_val_seq)\n",
    "X_test_seq  = np.array(X_test_seq)\n",
    "\n",
    "y_train = np.array(y_train)\n",
    "y_val   = np.array(y_val)\n",
    "y_test  = np.array(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c4a386de-2941-4852-99cb-775df176b352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ bidirectional_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ ?                      â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ bidirectional_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)         â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ bidirectional_4 (\u001b[38;5;33mBidirectional\u001b[0m) â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ ?                      â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ bidirectional_5 (\u001b[38;5;33mBidirectional\u001b[0m) â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = build_bilstm()\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a02490ad-1581-40e9-bcf5-b5c49bd6bb32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 276ms/step - accuracy: 1.0000 - loss: 0.0083 - val_accuracy: 1.0000 - val_loss: 6.0584e-05\n",
      "Epoch 2/5\n",
      "\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 286ms/step - accuracy: 1.0000 - loss: 4.3716e-05 - val_accuracy: 1.0000 - val_loss: 2.6600e-05\n",
      "Epoch 3/5\n",
      "\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 303ms/step - accuracy: 1.0000 - loss: 2.1634e-05 - val_accuracy: 1.0000 - val_loss: 1.4421e-05\n",
      "Epoch 4/5\n",
      "\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 293ms/step - accuracy: 1.0000 - loss: 1.2390e-05 - val_accuracy: 1.0000 - val_loss: 9.2556e-06\n",
      "Epoch 5/5\n",
      "\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 406ms/step - accuracy: 1.0000 - loss: 8.4364e-06 - val_accuracy: 1.0000 - val_loss: 6.6360e-06\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train_seq, y_train,\n",
    "    validation_data=(X_val_seq, y_val),\n",
    "    epochs=5,\n",
    "    batch_size=128\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "47df32dc-7c63-4779-8d62-42d0188ec631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 6.6355e-06\n",
      "Clean Test Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(X_test_seq, y_test)\n",
    "print(\"Clean Test Accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "20859c3c-4fda-4795-812a-8c97b5baeccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "# 1ï¸âƒ£ Randomly remove 20% words\n",
    "def remove_words(text, ratio=0.2):\n",
    "    words = text.split()\n",
    "    if len(words) < 2:\n",
    "        return text\n",
    "    keep = max(1, int(len(words) * (1 - ratio)))\n",
    "    return \" \".join(random.sample(words, keep))\n",
    "\n",
    "\n",
    "# 2ï¸âƒ£ Introduce 10% spelling mistakes\n",
    "def spelling_noise(text, ratio=0.1):\n",
    "    words = text.split()\n",
    "    n = int(len(words) * ratio)\n",
    "\n",
    "    for i in random.sample(range(len(words)), min(n, len(words))):\n",
    "        if len(words[i]) > 2:\n",
    "            pos = random.randint(0, len(words[i]) - 2)\n",
    "            w = list(words[i])\n",
    "            w[pos], w[pos+1] = w[pos+1], w[pos]\n",
    "            words[i] = \"\".join(w)\n",
    "\n",
    "    return \" \".join(words)\n",
    "\n",
    "\n",
    "# 3ï¸âƒ£ Replace 20% words with synonyms\n",
    "def synonym_replace(text, ratio=0.2):\n",
    "    words = text.split()\n",
    "    n = int(len(words) * ratio)\n",
    "\n",
    "    for i in random.sample(range(len(words)), min(n, len(words))):\n",
    "        syns = wordnet.synsets(words[i])\n",
    "        if syns:\n",
    "            words[i] = syns[0].lemmas()[0].name()\n",
    "\n",
    "    return \" \".join(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "270a9f51-772c-4cef-ab50-5d45c72426d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_noisy = []\n",
    "\n",
    "for text in X_test:\n",
    "    t = remove_words(text, ratio=0.2)\n",
    "    t = spelling_noise(t, ratio=0.1)\n",
    "    t = synonym_replace(t, ratio=0.2)\n",
    "    X_test_noisy.append(t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5e6b63d7-b578-436e-a5b1-a43a2adbe67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "X_test_noisy_seq = pad_sequences(\n",
    "    keras_tokenizer.texts_to_sequences(X_test_noisy),\n",
    "    maxlen=200\n",
    ")\n",
    "\n",
    "X_test_noisy_seq = np.array(X_test_noisy_seq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3af78d48-2575-4fca-9d88-0f0d326c9a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 6.6344e-06\n",
      "Noisy Test Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "loss_noisy, acc_noisy = model.evaluate(\n",
    "    X_test_noisy_seq,\n",
    "    np.array(y_test),\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Noisy Test Accuracy:\", acc_noisy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1e243d-c203-47b9-8ed6-5604d761d66b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
